{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hbtnnSYpZ_kh"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import re\n",
        "import scipy.io as scio\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import pickle\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8BhZtgIfZ_kx"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import torch\n",
        "\n",
        "exp = '12DriveEndFault'\n",
        "with open('cwru_data.pkl', 'rb') as file:\n",
        "    # Deserialize the dictionary\n",
        "    loaded_dict = pickle.load(file)\n",
        "\n",
        "data, labels = loaded_dict[exp]\n",
        "normal_data, normal_labels = loaded_dict['Normal']\n",
        "\n",
        "data = np.concatenate([data, normal_data], axis=0)\n",
        "labels = np.concatenate([labels, normal_labels], axis=0)\n",
        "\n",
        "data = data[:,:, np.newaxis]\n",
        "\n",
        "# scaler = MinMaxScaler()\n",
        "# data = scaler.fit_transform(data.reshape(-1, data.shape[1])).reshape(data.shape)\n",
        "\n",
        "# data = data[:, :, np.newaxis]\n",
        "\n",
        "# input_dim = data.shape[2]\n",
        "# hidden_dim = 128\n",
        "# num_layers = 3\n",
        "# batch_size = 64\n",
        "# num_epochs = 200\n",
        "# base_path = 'GAN/GAN_'\n",
        "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "vchq-xdO11OG"
      },
      "outputs": [],
      "source": [
        "## Newtork parameters\n",
        "parameters = dict()\n",
        "\n",
        "parameters['module'] = 'lstm'\n",
        "parameters['hidden_dim'] = 24\n",
        "parameters['num_layer'] = 3\n",
        "parameters['iterations'] = 5000\n",
        "parameters['batch_size'] = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FeSSTILzjJUG",
        "outputId": "06f13227-ede5-4f5b-9fdc-7b0def88ffb1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ],
      "source": [
        "print(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "V_idUU0AaXhD"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "5OYkKP-1mF7c"
      },
      "outputs": [],
      "source": [
        "from timegan import timegan\n",
        "from cwru import faults_idx, exps_idx"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "id": "AryMVRJKZ_kz",
        "outputId": "f57d850d-891f-4848-bb29-76b73d605cff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/timegan.py:121: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  X_mb = torch.tensor(X_mb, dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0/5000, e_loss_t0: 0.0281\n",
            "Step: 1000/5000, e_loss_t0: 0.0001\n",
            "Step: 2000/5000, e_loss_t0: 0.0000\n",
            "Step: 3000/5000, e_loss_t0: 0.0000\n",
            "Step: 4000/5000, e_loss_t0: 0.0000\n",
            "Finish Embedding Network Training\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/timegan.py:144: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Z_mb = torch.tensor(random_generator(batch_size, z_dim, T_mb, max_seq_len), dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0/5000, G_loss_S: 0.0028\n",
            "Step: 1000/5000, G_loss_S: 0.0000\n",
            "Step: 2000/5000, G_loss_S: 0.0000\n",
            "Step: 3000/5000, G_loss_S: 0.0000\n",
            "Step: 4000/5000, G_loss_S: 0.0000\n",
            "Finish Training with Supervised Loss Only\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/timegan.py:166: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  Z_mb = torch.tensor(random_generator(batch_size, z_dim, T_mb, max_seq_len), dtype=torch.float32)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step: 0/5000, D_loss: 1.3954, G_loss: 0.9874\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-c0d2d15e2057>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mX_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_train\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mX_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0mgenerated_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimegan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0mhistory\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mX_augmented\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerated_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/timegan.py\u001b[0m in \u001b[0;36mtimegan\u001b[0;34m(ori_data, parameters)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m             \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m             \u001b[0mG_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m             \u001b[0mg_optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    579\u001b[0m                 \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    580\u001b[0m             )\n\u001b[0;32m--> 581\u001b[0;31m         torch.autograd.backward(\n\u001b[0m\u001b[1;32m    582\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    345\u001b[0m     \u001b[0;31m# some Python versions print out the first line of a multi-line function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;31m# calls in the traceback and some print out the last line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m     _engine_run_backward(\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/autograd/graph.py\u001b[0m in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    823\u001b[0m         \u001b[0munregister_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_register_logging_hooks_on_whole_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 825\u001b[0;31m         return Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    826\u001b[0m             \u001b[0mt_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m         )  # Calls into the C++ engine to run the backward pass\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
        "\n",
        "X_augmented = []\n",
        "y_augmented = []\n",
        "histories = {}\n",
        "for label in np.unique(y_train):\n",
        "    X_label = X_train[y_train == label]\n",
        "    if X_label.shape[0] > 0:\n",
        "        generated_data, history = timegan(X_label, parameters)\n",
        "        history[label] = history\n",
        "        X_augmented.append(generated_data)\n",
        "\n",
        "        y_augmented.extend([label] * generated_data.shape[0])\n",
        "X_augmented = np.concatenate(X_augmented, axis=0)\n",
        "y_augmented = np.array(y_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yF_uOZSDrYRr"
      },
      "outputs": [],
      "source": [
        "n_classes = np.max(y_train, axis=0)+1\n",
        "# Étape 1 : Préparer les données\n",
        "# Combiner les données d'entraînement et leurs augmentations\n",
        "X_train_combined = np.concatenate([X_train, X_augmented], axis=0)\n",
        "y_train_combined = np.concatenate([y_train, y_augmented], axis=0)\n",
        "\n",
        "# Créer des ensembles de données au format PyTorch\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(X_train, dtype=torch.float32),\n",
        "    torch.tensor(np.eye(n_classes)[y_train], dtype=torch.long)\n",
        ")\n",
        "\n",
        "train_augmented_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(X_train_combined, dtype=torch.float32),\n",
        "    torch.tensor(np.eye(n_classes)[y_train_combined], dtype=torch.long)\n",
        ")\n",
        "\n",
        "test_dataset = torch.utils.data.TensorDataset(\n",
        "    torch.tensor(X_test, dtype=torch.float32),\n",
        "    torch.tensor(np.eye(n_classes)[y_test], dtype=torch.long)\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yok45c9JRYfz"
      },
      "outputs": [],
      "source": [
        "from evaluation import kl_divergence\n",
        "\n",
        "kl_divergence(torch.from_numpy(X_train), torch.from_numpy(X_augmented))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Lj1B1JbRY9a"
      },
      "outputs": [],
      "source": [
        "from evaluation import visualization\n",
        "\n",
        "visualization(X_train, X_augmented)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XYwsqEegrtTx"
      },
      "outputs": [],
      "source": [
        "from evaluation import model_evaluation\n",
        "\n",
        "input_size = X_train.shape[1]  # Dimensions des caractéristiques (features)\n",
        "\n",
        "# Évaluer sur les données d'entraînement d'origine\n",
        "print(\"\\n### Évaluation sur le jeu d'entraînement d'origine ###\")\n",
        "results_original = model_evaluation(\n",
        "    train_dataset=train_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    input_size=input_size,\n",
        "    num_classes=n_classes,\n",
        "    num_epochs=30,\n",
        "    device='cuda'\n",
        ")\n",
        "\n",
        "# Évaluer sur les données augmentées\n",
        "print(\"\\n### Évaluation sur le jeu d'entraînement augmenté ###\")\n",
        "results_augmented = model_evaluation(\n",
        "    train_dataset=train_augmented_dataset,\n",
        "    test_dataset=test_dataset,\n",
        "    input_size=input_size,\n",
        "    num_classes=n_classes,\n",
        "    num_epochs=30,\n",
        "    device='cuda'\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfWQQVvg2SbD"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Extract test accuracies for each model from both results\n",
        "models = list(results_original.keys())\n",
        "test_accuracies_original = [results_original[model]['test_accuracy'] for model in models]\n",
        "test_accuracies_augmented = [results_augmented[model]['test_accuracy'] for model in models]\n",
        "\n",
        "# Create the bar plot\n",
        "bar_width = 0.35\n",
        "index = range(len(models))\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "\n",
        "bar1 = ax.bar(index, test_accuracies_original, bar_width, label='Original')\n",
        "bar2 = ax.bar([i + bar_width for i in index], test_accuracies_augmented, bar_width, label='Augmented')\n",
        "\n",
        "# Labeling\n",
        "ax.set_xlabel('Model', fontsize=12)\n",
        "ax.set_ylabel('Test Accuracy', fontsize=12)\n",
        "ax.set_title('Comparison of Test Accuracy for Different Models', fontsize=14)\n",
        "ax.set_xticks([i + bar_width / 2 for i in index])\n",
        "ax.set_xticklabels(models)\n",
        "ax.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rR0xBIVGv0Bb"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrices(results_dict, y_test, title_prefix):\n",
        "    \"\"\"\n",
        "    Plot confusion matrices for all models in a results dictionary.\n",
        "\n",
        "    Parameters:\n",
        "        results_dict (dict): Dictionary containing model results, with a 'preds' key for predictions.\n",
        "        y_test (array-like): Ground truth labels.\n",
        "        title_prefix (str): Prefix for the title of each plot.\n",
        "    \"\"\"\n",
        "    num_models = len(results_dict)\n",
        "    fig, axes = plt.subplots(1, num_models, figsize=(5 * num_models, 5))\n",
        "\n",
        "    if num_models == 1:\n",
        "        axes = [axes]  # Ensure axes is iterable for a single plot.\n",
        "\n",
        "    for ax, (model_name, model_results) in zip(axes, results_dict.items()):\n",
        "        preds = model_results.get('preds', [])\n",
        "        if len(preds) == 0:\n",
        "            print(f\"No predictions found for model {model_name}. Skipping...\")\n",
        "            continue\n",
        "        cm = confusion_matrix(y_test, preds)\n",
        "        sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", cbar=False, ax=ax)\n",
        "        ax.set_title(f\"{title_prefix} - {model_name}\")\n",
        "        ax.set_xlabel(\"Predicted\")\n",
        "        ax.set_ylabel(\"True\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Exemple d'utilisation\n",
        "# Remplace `results_original` et `results_augmented` par tes dictionnaires et `y_test` par les labels réels.\n",
        "plot_confusion_matrices(results_original, y_test, \"Original\")\n",
        "plot_confusion_matrices(results_augmented, y_test, \"Augmented\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "T1VjFOelwWHl"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}